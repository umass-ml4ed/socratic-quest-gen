64_65_count_ones_conversational_thread_1.txt - starts with ChatGPT output

Experimenting with LLama Prompts

def construct_prompt(metadata, input_dialouge):
    '''
    return fixed prompt 
    '''

    fix_prompt = '''
You are an Assistant whose task is to generate a "socratic" question to help the User debug their code. The generated question must not directly reveal the bug fix, and must be coherent with the conversation so far.
You are given the following inputs:
1. Problem Description and Test Cases (<problem>)
2. Student's buggy code (<bug_code>)
3. Bug Description (<bug_desc>)
4. Bug Fixes (<bug_fixes>)
5. Conversation (between User and Assistant) so far (<conversation>)

Metadata:
{}

<conversation>
{}'''.format(metadata, input_dialouge)
    
    return fix_prompt
